{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3NEe4BojNQs"
   },
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrWhZK_sjJWd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import random\n",
    "import wget\n",
    "random.seed()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Please add necessary imports here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccMNbLzljJWl"
   },
   "outputs": [],
   "source": [
    "filename = wget.download(\"https://github.com/MIE1513HS-2022/course-datasets/raw/main/20_newsgroups.zip\")\n",
    "!unzip 20_newsgroups.zip\n",
    "DATA_DIR = \"20_newsgroups\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAOneB4BjJWq"
   },
   "source": [
    "## Functions from lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**PLEASE DO NOT CHANGE FUNCTION/CLASS NAMES**\n",
    "\n",
    "**PLEASE DO NOT CHANGE/OVERWRITE COMPLETED FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isVIWKz5jJWr"
   },
   "outputs": [],
   "source": [
    "def clean_file_text(text):\n",
    "    new_text = re.sub(\"Newsgroups:.*?\\n\", \"\", text)\n",
    "    new_text = re.sub(\"Xref:.*?\\n\", \"\", new_text)\n",
    "    new_text = re.sub(\"Path:.*?\\n\", \"\", new_text)\n",
    "    new_text = re.sub(\"Date:.*?\\n\", \"\", new_text)\n",
    "    new_text = re.sub(\"Followup-To:.*?\\n\", \"\", new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HHTRr8CjJWv"
   },
   "outputs": [],
   "source": [
    "def corpus_count_words(file_list):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_counter = Counter()\n",
    "    for file_path in file_list:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            file_data = file.read()\n",
    "            file_data = clean_file_text(file_data)\n",
    "            file_words = tokenizer.tokenize(file_data)\n",
    "            word_counter.update(file_words)\n",
    "    return word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VBp_7RBjJW1"
   },
   "outputs": [],
   "source": [
    "def get_topic_name(file_path):\n",
    "    return file_path.parent.name\n",
    "\n",
    "def get_target(topic_name):\n",
    "    topics = ['talk.politics.mideast', 'rec.autos', 'comp.sys.mac.hardware', 'alt.atheism', 'rec.sport.baseball', \n",
    "     'comp.os.ms-windows.misc', 'rec.sport.hockey', 'sci.crypt', 'sci.med', 'talk.politics.misc', \n",
    "     'rec.motorcycles', 'comp.windows.x', 'comp.graphics', 'comp.sys.ibm.pc.hardware', 'sci.electronics',\n",
    "     'talk.politics.guns', 'sci.space', 'soc.religion.christian', 'misc.forsale', 'talk.religion.misc']\n",
    "    return topics.index(topic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OH81rhWjjJW4"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm):\n",
    "    # plot the confusion matrix\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.matshow(cm, fignum=1)\n",
    "    \n",
    "    # add labels for all targets\n",
    "    num_targets = cm.shape[0]\n",
    "    plt.xticks(list(range(num_targets+1)))\n",
    "    plt.yticks(list(range(num_targets+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MLQ1():\n",
    "    def binary_baseline_data(self, file_list, num_words=1000):\n",
    "        # Calculate word count in corpus\n",
    "        news_cnt = corpus_count_words(file_list)\n",
    "\n",
    "        # Select the most common numWords\n",
    "        word_list = [word for (word, freq) in news_cnt.most_common(num_words)]\n",
    "\n",
    "        # Create a binary encoding of dataset based on the selected features (X)\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        df_rows = []\n",
    "        for file_path in file_list:\n",
    "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                file_data = file.read()\n",
    "                file_data = clean_file_text(file_data)\n",
    "                file_words = tokenizer.tokenize(file_data)\n",
    "                df_rows.append([1 if word in file_words else 0 for word in word_list])\n",
    "        X = pd.DataFrame(df_rows, index=[str(f) for f in file_list], columns = word_list)\n",
    "\n",
    "        # Create a dataframe of targets (y)\n",
    "        y = [get_target(get_topic_name(file_path)) for file_path in file_list]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def binary_improved_data(self, file_list, num_words=1000):\n",
    "        # Put your code here for Q1b\n",
    "        # Make sure you update the variable features and targets below\n",
    "\n",
    "        X = None\n",
    "        y = None\n",
    "\n",
    "        # Please remember to put index for your dataframe as the file name\n",
    "        # For example: pd.DataFrame(data, index=[str(f) for f in file_list],columns=[])\n",
    "\n",
    "        # validate return types\n",
    "        assert isinstance(X, pd.DataFrame) and isinstance(y, list), \"return types\"\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def train_and_predict_baseline(self, file_list):\n",
    "        # get the baseline data\n",
    "        X, y = self.binary_baseline_data(file_list)\n",
    "\n",
    "        # split to train and test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        # train a logistic regression classifier\n",
    "        clf = LogisticRegression(C=1.0).fit(X_train, y_train)\n",
    "\n",
    "        # predict on train and test set\n",
    "        y_train_predict = clf.predict(X_train)\n",
    "        y_test_predict = clf.predict(X_test)\n",
    "\n",
    "        # calculate train and test accuracy\n",
    "        train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "        return X, y, train_accuracy, test_accuracy\n",
    "\n",
    "    def train_and_predict_improved(self, file_list):\n",
    "        # get the baseline data\n",
    "        X, y = self.binary_improved_data(file_list)\n",
    "\n",
    "        # Write your code here for Q1c:\n",
    "        # You need to split the data and train a logistic regression classifier.\n",
    "        # Then, you need to calculate the variables train_accuracy and test_accuracy for the new classifier\n",
    "\n",
    "        return X, y, train_accuracy, test_accuracy\n",
    "\n",
    "    @staticmethod\n",
    "    def random_mean_ci(X, y, num_tests):\n",
    "        # train_results is a list of train accuracy results for the differrent random splits of the dataset\n",
    "        train_results = []\n",
    "\n",
    "        # test_results is a list of test accuracy results for the differrent random splits of the dataset\n",
    "        test_results = []\n",
    "\n",
    "        # Write your code here for Q1d\n",
    "\n",
    "        # calculate the train mean and the 95% confidence interval for the list of results\n",
    "        train_mean = np.mean(train_results)\n",
    "        train_ci_low, train_ci_high = stats.t.interval(0.95, len(train_results)-1, loc=train_mean, scale=stats.sem(train_results))\n",
    "\n",
    "        # calculate the test mean and the 95% confidence interval for the list of results\n",
    "        test_mean = np.mean(test_results)\n",
    "        test_ci_low, test_ci_high = stats.t.interval(0.95, len(test_results)-1, loc=test_mean, scale=stats.sem(test_results))\n",
    "\n",
    "        # validate return types\n",
    "        assert isinstance(train_mean, float) and isinstance(train_ci_low, float) and isinstance(train_ci_high, float), \"return types\"\n",
    "        assert isinstance(test_mean, float) and isinstance(test_ci_low, float) and isinstance(test_ci_high, float), \"return types\"\n",
    "\n",
    "        return train_mean, train_ci_low, train_ci_high, test_mean, test_ci_low, test_ci_high\n",
    "\n",
    "    @staticmethod\n",
    "    def random_cm(X, y, num_tests):\n",
    "        # cm_list is a list of confusion matrices for the different random splits of the dataset\n",
    "        cm_list = []\n",
    "\n",
    "        # Write your code here for Q1f\n",
    "\n",
    "        # sum the confusion matrices and return the combined confusion matrix\n",
    "        combined_cm = np.array(cm_list).sum(axis=0)\n",
    "\n",
    "        # validate return type\n",
    "        assert isinstance(combined_cm, np.ndarray), \"return type\"\n",
    "\n",
    "        return combined_cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Please do not change this global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwVZblX1jJW9"
   },
   "outputs": [],
   "source": [
    "all_files = [pth for pth in Path(DATA_DIR).glob(\"**/*\") if pth.is_file() and not pth.name.startswith(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hV2I4MIDjJXF"
   },
   "outputs": [],
   "source": [
    "q1 = MLQ1()\n",
    "X, y, train_accuracy, test_accuracy = q1.train_and_predict_baseline(all_files)\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZSQINnXjJXJ"
   },
   "source": [
    "### Q1 (a)\n",
    "\n",
    "[Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XFlNTqFjJXL"
   },
   "source": [
    "### Q1 (b)\n",
    "\n",
    "Implement *binary_improved_data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXRUw2LDjJXQ"
   },
   "source": [
    "### Q1 (c)\n",
    "\n",
    "Implement *train_and_predict_improved*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2wliJNvjJXR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, y, train_accuracy, test_accuracy = q1.train_and_predict_improved(all_files)\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SST3B968jJXX"
   },
   "source": [
    "[Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2EbQVhMjJXY"
   },
   "source": [
    "### Q1 (d)\n",
    "\n",
    "Implement *random_mean_ci*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrNbYeqqjJXc"
   },
   "source": [
    "### Q1 (e)\n",
    "\n",
    "Use the following code to calculate the mean accuracy and 95% confidence interval over 10 random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oerfu1GljJXd"
   },
   "outputs": [],
   "source": [
    "train_mean10, train_low10, train_high10, test_mean10, test_low10, test_high10 = MLQ1.random_mean_ci(X, y, num_tests = 10)\n",
    "print(\"Train mean accuracy over 10 random splits: {}\".format(train_mean10))\n",
    "print(\"Train confidence interval over 10 random splits: [{}, {}]\".format(train_low10, train_high10))\n",
    "print(\"Test mean accuracy over 10 random splits: {}\".format(test_mean10))\n",
    "print(\"Test confidence interval over 10 random splits: [{}, {}]\".format(test_low10, test_high10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWqqzPkGjJXh"
   },
   "source": [
    "[ Write your answer here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z86lxUvmjJXi"
   },
   "source": [
    "### Q1 (f)\n",
    "\n",
    "Implement *random_cm*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e19w779ejJXs"
   },
   "source": [
    "### Q1 (g)\n",
    "\n",
    "Use the following code to produce a confusion matrix for 10 random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXGSnr-xjJXt"
   },
   "outputs": [],
   "source": [
    "cm10 = MLQ1.random_cm(X, y, num_tests = 10)\n",
    "plot_confusion_matrix(cm10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXgq9z3KjJXw"
   },
   "source": [
    "[ Write your answer here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTFCjNAjjJXx"
   },
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MLQ2():\n",
    "    def feature_num(self, X, y):\n",
    "        # result_list is a list of tuples (num_features, train_accuracy, test_accuracy)\n",
    "        # where numFeatures is the number of words used as features\n",
    "        result_list = []\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        for p in [0.1, 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "            subset_size = int(p*X.shape[1])\n",
    "            X_train_subset = X_train.iloc[:, 0:subset_size]\n",
    "            X_test_subset = X_test.iloc[:, 0:subset_size]\n",
    "            # Write your code here to calculate train_accuracy and test_accuracy for the current subset of features\n",
    "            # ......\n",
    "            train_accuracy = None\n",
    "            test_accuracy = None\n",
    "            # add to result_list\n",
    "            result_list.append((p, train_accuracy, test_accuracy))\n",
    "\n",
    "        # Make a dataframe of the results\n",
    "        result_df = pd.DataFrame(result_list, columns=[\"num_features\", \"train_accuracy\", \"test_accuracy\"])\n",
    "\n",
    "        # validate return type\n",
    "        assert isinstance(result_df, pd.DataFrame), \"return type\"\n",
    "\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhXfPuIpjJXy"
   },
   "source": [
    "### Q2 (a)\n",
    "\n",
    "Implement *feature_num*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7hNvwoljJX6"
   },
   "source": [
    "### Q2 (b)\n",
    "\n",
    "Use the following code to plot the train and test accuracy for the different feature sets sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ehilq_hyjJX7"
   },
   "outputs": [],
   "source": [
    "q2 = MLQ2()\n",
    "feature_num_df = q2.feature_num(X, y)\n",
    "feature_num_df.plot(x=\"num_features\", y=[\"train_accuracy\", \"test_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFk_ess_jJYC"
   },
   "source": [
    "[ Write your answer here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0ZftHo6jJYD"
   },
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MLQ3():\n",
    "    def hyperparameter(self, X, y):\n",
    "        # result_list is a list of tuples (num_features, train_accuracy, test_accuracy)\n",
    "        # where numFeatures is the number of words used as features\n",
    "        result_list = []\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        for param in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "            # Write your code here to calculate train_accuracy and test_accuracy for the current parameter value\n",
    "            # ......\n",
    "            train_accuracy = None\n",
    "            test_accuracy = None\n",
    "\n",
    "            # add to result_list\n",
    "            result_list.append((param, train_accuracy, test_accuracy))\n",
    "\n",
    "        # Make a dataframe of the results\n",
    "        result_df = pd.DataFrame(result_list, columns=[\"param\", \"train_accuracy\", \"test_accuracy\"])\n",
    "\n",
    "        # validate return type\n",
    "        assert isinstance(result_df, pd.DataFrame), \"return type\"\n",
    "\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0e1QSDsjJYE"
   },
   "source": [
    "### Q3 (a)\n",
    "\n",
    "Implement *hyperparameter*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Id6-n2ZBjJYM"
   },
   "source": [
    "### Q3 (b)\n",
    "\n",
    "Use the following code to plot the train and test accuracy for the different the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phBkJ5mvjJYN"
   },
   "outputs": [],
   "source": [
    "q3 = MLQ3()\n",
    "param_df = q3.hyperparameter(X, y)\n",
    "param_df.plot(x=\"param\", y=[\"train_accuracy\", \"test_accuracy\"], logx=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngW4KMVLjJYP"
   },
   "source": [
    "[ Write your answer here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPsJTYu_jJYR"
   },
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MLQ4():\n",
    "    def tf_improved_data(self, file_list, num_words = 1000):\n",
    "        # Put your code here\n",
    "        # Make sure you update the variable features and targets below\n",
    "\n",
    "        X = None\n",
    "        y = None\n",
    "\n",
    "        # validate return types\n",
    "        assert isinstance(X, pd.DataFrame) and isinstance(y, list), \"return types\"\n",
    "\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aK7nTn82jJYS"
   },
   "source": [
    "### Q4 (a)\n",
    "\n",
    "Implement *tf_improved_data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1Ws8ZgrjJYV"
   },
   "source": [
    "### Q4 (b)\n",
    "\n",
    "Use the following code to calculate the mean accuracy and 95% confidence interval over multiple random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9c3b_RwjJYW"
   },
   "outputs": [],
   "source": [
    "q4 = MLQ4()\n",
    "X_tf, y_tf = q4.tf_improved_data(all_files)\n",
    "train_mean10, train_low10, train_high10, test_mean10, test_low10, test_high10 = MLQ1.random_mean_ci(X_tf, y_tf, num_tests = 10)\n",
    "print(\"Train mean accuracy over 10 random splits: {}\".format(train_mean10))\n",
    "print(\"Train confidence interval over 10 random splits: [{}, {}]\".format(train_low10, train_high10))\n",
    "print(\"Test mean accuracy over 10 random splits: {}\".format(test_mean10))\n",
    "print(\"Test confidence interval over 10 random splits: [{}, {}]\".format(test_low10, test_high10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKgIMSPRjJYc"
   },
   "source": [
    "[ Write your answer here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAfgSoqjjJYd"
   },
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MLQ5():\n",
    "    def nb_random_mean_ci(self, X, y, num_tests):\n",
    "        # train_results is a list of train accuracy results for the differrent random splits of the dataset\n",
    "        train_results = []\n",
    "\n",
    "        # test_results is a list of test accuracy results for the differrent random splits of the dataset\n",
    "        test_results = []\n",
    "\n",
    "        # Write your code here\n",
    "\n",
    "        # calculate the train mean and the 95% confidence interval for the list of results\n",
    "        train_mean = np.mean(train_results)\n",
    "        train_ci_low, train_ci_high = stats.t.interval(0.95, len(train_results)-1, loc=train_mean, scale=stats.sem(train_results))\n",
    "\n",
    "        # calculate the test mean and the 95% confidence interval for the list of results\n",
    "        test_mean = np.mean(test_results)\n",
    "        test_ci_low, test_ci_high = stats.t.interval(0.95, len(test_results)-1, loc=test_mean, scale=stats.sem(test_results))\n",
    "\n",
    "        # validate return types\n",
    "        assert isinstance(train_mean, float) and isinstance(train_ci_low, float) and isinstance(train_ci_high, float), \"return types\"\n",
    "        assert isinstance(test_mean, float) and isinstance(test_ci_low, float) and isinstance(test_ci_high, float), \"return types\"\n",
    "\n",
    "        return train_mean, train_ci_low, train_ci_high, test_mean, test_ci_low, test_ci_high\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tV_h9kGjJYg"
   },
   "source": [
    "### Q5 (a)\n",
    "\n",
    "Implement *nb_random_mean_ci*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9-OzAIUjJYj"
   },
   "source": [
    "### Q5 (b)\n",
    "\n",
    "Use the following code to calculate the mean accuracy and 95% confidence interval over multiple random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9Me9H6HjJYk"
   },
   "outputs": [],
   "source": [
    "q5 = MLQ5()\n",
    "train_mean10, train_low10, train_high10, test_mean10, test_low10, test_high10 = q5.nb_random_mean_ci(X, y, num_tests = 10)\n",
    "print(\"Train mean accuracy over 10 random splits: {}\".format(train_mean10))\n",
    "print(\"Train confidence interval over 10 random splits: [{}, {}]\".format(train_low10, train_high10))\n",
    "print(\"Test mean accuracy over 10 random splits: {}\".format(test_mean10))\n",
    "print(\"Test confidence interval over 10 random splits: [{}, {}]\".format(test_low10, test_high10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P99mWvAbjJYp"
   },
   "source": [
    "[ Write your answer here ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CPzZDj-jJYq"
   },
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MLQ6():\n",
    "    def binary_med_data(self, file_list, num_words = 1000):\n",
    "        # Put your code here\n",
    "        # Make sure you update the variable features and targets below\n",
    "\n",
    "        X = None\n",
    "        y = None\n",
    "\n",
    "        #Please remember to put index for your dataframe as the file name\n",
    "        #For example: pd.DataFrame(data, index=[str(f) for f in file_list],columns=[])\n",
    "\n",
    "        # validate return types\n",
    "        assert isinstance(X, pd.DataFrame) and isinstance(y, list), \"return types\"\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWL6L_OUjJYu"
   },
   "source": [
    "### Q6 (a)\n",
    "\n",
    "Implement *binary_med_data*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Z3uKy8WjJYx"
   },
   "source": [
    "### Q6 (b)\n",
    "\n",
    "Use the following code to calculate the mean accuracy and 95% confidence interval over multiple random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3Dfy0uIjJYy"
   },
   "outputs": [],
   "source": [
    "q6 = MLQ6()\n",
    "X, y = q6.binary_med_data(all_files)\n",
    "train_mean10, train_low10, train_high10, test_mean10, test_low10, test_high10 = MLQ1.random_mean_ci(X, y, num_tests = 10)\n",
    "print(\"Train mean accuracy over 10 random splits: {}\".format(train_mean10))\n",
    "print(\"Train confidence interval over 10 random splits: [{}, {}]\".format(train_low10, train_high10))\n",
    "print(\"Test mean accuracy over 10 random splits: {}\".format(test_mean10))\n",
    "print(\"Test confidence interval over 10 random splits: [{}, {}]\".format(test_low10, test_high10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EueLolt1jJY0"
   },
   "source": [
    "[ Write your answer here ]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ml_assignment.ipynb",
   "provenance": [
    {
     "file_id": "1aaud2_eLn13hTR4i-g8sI_8fhD9u_ac-",
     "timestamp": 1613968446899
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
