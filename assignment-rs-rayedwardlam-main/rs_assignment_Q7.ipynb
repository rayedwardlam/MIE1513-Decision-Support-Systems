{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1Qk4-t7mhAr"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "!pip install wget\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from heapq import nlargest\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cu-OohvmhAs"
      },
      "outputs": [],
      "source": [
        "wget.download(\"https://github.com/MIE1513HS-2022/course-datasets/raw/main/ml-100k.zip\", \"ml-100k.zip\")\n",
        "!unzip ml-100k.zip\n",
        "MOVIELENS_DIR = \"ml-100k\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VzPEIDEmhAt"
      },
      "outputs": [],
      "source": [
        "!ls {MOVIELENS_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkRfDwZAmhAt"
      },
      "outputs": [],
      "source": [
        "def getData(folder_path, file_name):\n",
        "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
        "    return data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9KEENcumhAt"
      },
      "outputs": [],
      "source": [
        "rating_df = getData(MOVIELENS_DIR, 'u.data')\n",
        "rating_df_train = getData(MOVIELENS_DIR, 'u1.base')\n",
        "rating_df_test = getData(MOVIELENS_DIR, 'u1.test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1FdxrWTmhAt"
      },
      "outputs": [],
      "source": [
        "class CrossValidation(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "            'RPrecision': self.rprecision\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items retrived\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "    \n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "    \n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "\n",
        "    def rprecision(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame.\n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet = self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRPs = 0\n",
        "        countRPs = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID, :]\n",
        "\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID, :]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            topK = nlargest(len(userTestVector), range(len(userVector)), userVector.take)\n",
        "            # Calculate recall\n",
        "            rp = float(len([item for item in topK if item in userTestVector])) / len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRPs += rp\n",
        "            countRPs += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRPs) / countRPs\n",
        "\n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "    \n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "            \n",
        "        return matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms. \n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkkuVeqdmhAv"
      },
      "source": [
        "## Q8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6BittTKmhAw"
      },
      "outputs": [],
      "source": [
        "def dataPreprocessor(rating_df, num_users, num_items):\n",
        "    \"\"\"\n",
        "        INPUT: \n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
        "            num_row: int. number of users\n",
        "            num_col: int. number of items\n",
        "            \n",
        "        OUTPUT:\n",
        "            matrix: 2D numpy array. \n",
        "            \n",
        "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
        "            \n",
        "        NOTE 2: data can have more columns, but your function should ignore \n",
        "              additional columns.\n",
        "    \"\"\"\n",
        "    ########### your code goes here ###########\n",
        "\n",
        "    \n",
        "    \n",
        "    ###########         end         ###########\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1VQVWNmmhAw"
      },
      "outputs": [],
      "source": [
        "class CompetitionRecSys(object):\n",
        "    \"\"\"\n",
        "    You can define new methods if you need. Don't use global variables in the class. \n",
        "    \"\"\"\n",
        "    def __init__(self, ):\n",
        "        \"\"\"\n",
        "        Initialization of the class\n",
        "        1. Make sure to fill out self.pred_column_name, the name you give  to your competition method\n",
        "        \n",
        "        \"\"\"\n",
        "        ########## your code goes here ###########\n",
        "        self.pred_column_name = None\n",
        "        ###########         end         ###########\n",
        "\n",
        "    def predict_all(self, train_vec, num_user, num_item):\n",
        "        \"\"\"\n",
        "        INPUT: \n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            num_user: scalar. number of users\n",
        "            num_item: scalar. number of items\n",
        "        OUTPUT:\n",
        "            no return... \n",
        "        \n",
        "        NOTES:\n",
        "            This function is where you train your model\n",
        "        \"\"\"\n",
        "                \n",
        "        ########## your code goes here ###########\n",
        "        pass\n",
        "        ###########         end         ###########\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "\n",
        "            NOTES:\n",
        "            This function is where your model makes prediction \n",
        "            Please fill out: prediction.loc[index, self.pred_column_name] = None                            \n",
        "                              \n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
        "        else:\n",
        "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            ########### your code goes here ###########\n",
        "            prediction.loc[index, self.pred_column_name] = None\n",
        "            ###########         end         ###########\n",
        "\n",
        "        return prediction\n",
        "          \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "        pass\n",
        "        ##########         end         ###########\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaD-h5VJmhAx"
      },
      "outputs": [],
      "source": [
        "competition = CompetitionRecSys()\n",
        "algorithm_instances = [competition]\n",
        "cv_rp = CrossValidation('RPrecision')\n",
        "rp = cv_rp.run(algorithm_instances,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2920D_pfmhAx"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghTzkuG_mhAx"
      },
      "outputs": [],
      "source": [
        "# Constants for validation only\n",
        "ROW_NUM = 943\n",
        "COL_NUM = 1682\n",
        "RATING_COL = 'rating'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siphHJBrmhAx"
      },
      "outputs": [],
      "source": [
        "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
        "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
        "    try:\n",
        "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    except:\n",
        "        print('dataPreprocessor function has error')\n",
        "        return\n",
        "    try:\n",
        "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return validation_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NF-mK3smhAx"
      },
      "outputs": [],
      "source": [
        "validation_df = validateDataPreprocessor()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "rs_assignment_Q7.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}